{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import chromadb\n",
    "import os\n",
    "from string import Template\n",
    "import gradio as gr\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "# Get current script directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# Path to key.rtf file\n",
    "key_file_path = os.path.join(current_dir, \"key.rtf\")\n",
    "\n",
    "# Read the API key from the .rtf file\n",
    "try:\n",
    "    with open(key_file_path, \"r\") as file:\n",
    "        raw_content = file.read()\n",
    "        # Extract plain text from RTF\n",
    "        openai_api_key = rtf_to_text(raw_content).strip()\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"API key file not found at: {key_file_path}\")\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"Error reading API key: {e}\")\n",
    "\n",
    "# Set OpenAI API Key\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = Template(\"\"\"\n",
    "You are an AI assistant specializing in answering questions based on provided context from a document. Your task is to use the context to answer questions accurately and concisely. If the context does not contain enough information to answer the question, say, \"The provided context does not contain sufficient information to answer this question.\"\n",
    "\n",
    "Context:\n",
    "${context}\n",
    "\n",
    "Question:\n",
    "${question}\n",
    "\n",
    "Answer concisely and clearly:\n",
    "\"\"\")\n",
    "\n",
    "# Function to generate a prompt using the template\n",
    "def generate_prompt(context, question):\n",
    "    return prompt_template.substitute(context=context, question=question)\n",
    "\n",
    "# Step 1: Load and Split PDF\n",
    "def process_pdf(pdf_name):\n",
    "    # Locate PDF file in the same folder\n",
    "    pdf_path = os.path.join(current_dir, pdf_name)\n",
    "    try:\n",
    "        # Load the PDF\n",
    "        loader = PyPDFLoader(pdf_path)  \n",
    "        documents = loader.load()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load the PDF: {e}\")\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Use new ChromaDB client configuration\n",
    "    collection = client.get_or_create_collection(\"pdf_chunks\")\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_id = f\"chunk_{i+1}\"\n",
    "        chunk_content = chunk.page_content\n",
    "\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
    "        collection.add(\n",
    "            documents=[chunk_content],\n",
    "            metadatas=[{\"chunk_id\": chunk_id}],\n",
    "            ids=[chunk_id]\n",
    "        )\n",
    "    print(\"All chunks have been processed and stored in ChromaDB.\")\n",
    "\n",
    "# Step 2: Question-Answering System\n",
    "def ask_question(query, collection_name=\"pdf_chunks\", n_results=3):\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results\n",
    "    )\n",
    "\n",
    "    if not results[\"documents\"] or not results[\"documents\"][0]:\n",
    "        return \"No relevant context found to answer your question.\"\n",
    "\n",
    "    context = \"\\n\".join(results[\"documents\"][0])\n",
    "    prompt = generate_prompt(context=context, question=query)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    answer = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return answer\n",
    "\n",
    "# Gradio Interface\n",
    "def chatbot_interface(user_question):\n",
    "    try:\n",
    "        answer = ask_question(user_question)\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Process the PDF (only needed once; comment out after first run)\n",
    "pdf_name = \"nestle.pdf\"\n",
    "process_pdf(pdf_name)\n",
    "\n",
    "# Build Gradio Interface\n",
    "gr_interface = gr.Interface(\n",
    "    fn=chatbot_interface,\n",
    "    inputs=gr.Textbox(label=\"Enter your question:\", placeholder=\"e.g., What is Nestle's shared responsibility?\"),\n",
    "    outputs=gr.Textbox(label=\"Answer:\"),\n",
    "    title=\"Nestle's AI Assistant\",\n",
    "    description=\"Ask questions based on the content of the uploaded PDF.\"\n",
    ")\n",
    "\n",
    "# Launch the Interface\n",
    "if __name__ == \"__main__\":\n",
    "    gr_interface.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
